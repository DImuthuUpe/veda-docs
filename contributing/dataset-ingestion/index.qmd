---
title: "Dataset Ingestion"
subtitle: "Guide to ingesting and publishing data to the VEDA data store & STAC API"
---

VEDA uses a centralized [Spatio-Temporal Asset Catalog (STAC)](https://stacspec.org/) for data dissemination and prefers to host datasets in cloud-object storage ([AWS S3](https://aws.amazon.com/s3/) in the region `us-west-2`)
in the cloud-optimized file formats [Cloud-Optimized GeoTIFF (COG)](https://www.cogeo.org/) and [Zarr](https://zarr.dev/), which enables viewing and efficient access in the cloud directly
from the original datafiles without copies or multiple versions.


## Steps for ingesting a dataset

For dataset ingestion, generally four steps are required. Depending on the capacity of the dataset provider, some of the steps can be completed by the VEDA team on request.

The data ingestion process requires `Cognito` credentials (username and password). In order to retrieve these credentials, you'll need to contact a member of the VEDA Data Services Team at [veda@uah.edu](mailto:veda@uah.edu) who can set up an account and credentials for you. The first time you log in using the `Cognito Client`, you will be prompted to set a new password.

Complete as many steps of the process as you have capacity or authorization to. Please follow the steps and guides outlined below: 

0. Open a dedicated [pull request in the veda-data repository](https://github.com/NASA-IMPACT/veda-data). Please read through these docs fully first as you they will help supply the information required to complete the PR. Use this ["new dataset" template to open a new issue and get started](https://github.com/NASA-IMPACT/veda-data/issues/new?assignees=&labels=dataset&projects=&template=new-dataset.yaml&title=New+Dataset%3A+%3Cdataset+title%3E). 
1. Transform datasets to conform with cloud-optimized file formats - see [file preparation](./file-preparation.qmd)
2. Upload files to storage (may be skipped, if data is cloud-optimized and in `us-west-2`)
3. Load those records into the VEDA STAC - see [catalog ingestion](./catalog-ingestion.qmd)

For a walk through of the full process outlined above, please refer to this [example notebook](https://github.com/NASA-IMPACT/veda-data/blob/main/transformation-scripts/example-template/example-geoglam-ingest.ipynb). This notebook uses the `GEOGLAM June 2023` dataset as an example, but please use this as a guide for the ingestion process (and required dataset defintions), replacing the GEOGLAM dataset with your own. 

Stuck on how to develop compliant metadata records for your dataset? 

Checkout the following notebooks and resources to help provide you with the STAC metadata required to [create the dataset definitions needed for catalog ingestion](https://nasa-impact.github.io/veda-docs/contributing/dataset-ingestion/catalog-ingestion.html).

- **How to create STAC Collections**: see this [example notebook](/notebooks/veda-operations/stac-collection-creation.html) and related STAC [conventions](./stac-collection-conventions.qmd) 
- **How to create STAC Items**:  see this [example notebook](/notebooks/veda-operations/stac-item-creation.html) and [conventions](./stac-item-conventions.qmd).